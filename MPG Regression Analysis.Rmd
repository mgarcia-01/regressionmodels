---
title: "MPG Regression Analysis"
author: "Michael Garcia"
date: "5/17/2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary

Motor Trend provides information, opinions, and tips about cars to its readers. A topic of interest is energy efficiency of vehicles, specifically autmatic and manual transimission and miles per gallon. The analysis will provide insight into the methods used and the results for answering the question is miles per gallon for automatic vehicles greater than, less than, or equal to vehicles with manual transmission.
      * “Is an automatic or manual transmission better for MPG”
      * "Quantify the MPG difference between automatic and manual transmissions"

The analysis includes to sets of stepped models. Those with "Model#" are Generalized Linear Model using binomial distribution and logiscit regression; "LModel#" are the models using Linear Models.

The question involves a response of binary data: is it MPG automatic or manual. The models tested involve linear models and generalized linear model with binomial family function. The coefficient of determination is highest for LModel5. However, the predictors have p-values indiciating they are not significant to the model. The question is whether there probability of a vehicle being automatic with higher miles per gallon. So the a logistic GLM is the better approach for binary outcome.


#### Exploratory Analysis



```{r cars}
data(cars)
summary(mtcars)
mtcarsdf <- as.data.frame(mtcars)

```

#### Exploratory Data Analysis- Distribution
The distributions for the mpg for the total dataset are reflected 

```{r distributions, echo=TRUE}
mtcarsdf$mpg_rnd <- round(mtcarsdf$mpg,0)

par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
hist(mtcarsdf$mpg,col = "blue", freq = TRUE, xlab = "MPG")
rug(mtcarsdf$mpg, col = "red")
abline(v = mean(mtcarsdf$mpg), col = "red", lwd = 4)
boxplot(mpg ~ am, data = mtcarsdf, col = "green", xlab = "Manual vs Automatic", ylab = "MPG")

```



You can also embed plots, for example:

```{r plots, include=FALSE, echo=FALSE}
	
cargrp <- aggregate(mtcars, by = list(mtcars$am), FUN = mean, na.rm = TRUE)
cargrp <- as.data.frame(cargrp)
cargrp <- aggregate(mtcars$am, list(mtcars$mpg), function(x) unique(x))
colnames(cargrp) <- c("mpg", "am")
print(cargrp)

```



#### Nested Fitting - Generalized Linear Model
```{r Gnestedfits, echo=TRUE}
Model1 <- glm(am ~ mpg , data = mtcars, family = "binomial") 
Model2 <- glm(am ~ mpg + wt, data = mtcars, family = "binomial") 
Model3 <- glm(am ~ mpg + wt + hp , data = mtcars, family = "binomial") 
Model4 <- glm(am ~ mpg + wt + hp+ disp, data = mtcars, family = "binomial") 
#Model5 <- glm(am ~ ., data = mtcars, family = "binomial")

```

#### ANOVA GLM
```{r glinearmodel, echo=TRUE}
anova(Model1, Model2, Model3, Model4)
```


#### Nested Fitting - Linear Model
```{r nestedfitsLM, echo=TRUE}
LModel1 <- lm(mpg ~ am , data = mtcars) 
LModel2 <- lm(mpg ~ am + wt, data = mtcars) 
LModel3 <- lm(mpg ~ am + wt + hp , data = mtcars) 
LModel4 <- lm(mpg ~ am + wt + hp+ disp, data = mtcars) 
LModel5 <- lm(mpg ~ ., data = mtcars)
```

#### ANOVA LM


```{r linearmodel, echo=TRUE}
anova(LModel1, LModel2, LModel3, LModel4, LModel5)
LModelSum1 <- summary(LModel1)
LModelSum2 <- summary(LModel2)
LModelSum3 <- summary(LModel3)
LModelSum4 <- summary(LModel4)
LModelSum5 <- summary(LModel5)
LModelSum1$r.squared
LModelSum2$r.squared
LModelSum3$r.squared
LModelSum4$r.squared
LModelSum5$r.squared
```

#### GLM

The model supports that the MPG increases for vehicles that are automatic or not automatic. We use binomial general linear model
given that 1 of 2 outcomes is possible for mileage per gallon.

The model is given by: probautomatic = .307MPG - 6.6035. So for every increase in distance of .307MPG theres a higher probabilty that the vehicle
is automatic.

```{r glm, echo=TRUE}
logCars <- glm(mtcars$am~ mtcars$mpg, family = "binomial")
summary(logCars)
logCars$fitted
```

#### GLM Summary
The models for the GLM are summarized here. The Akaike Information Criterion (aic) is proper for the model
as we are looking at the likelihood of the vehicle being either automatic or manual. The aic
 measures the dispersion of data points for models of likelihood. The AM = .307 - 6.60 has the largest AIC
 compared to the rest of the models

```{r GLM_Summary, echo=TRUE, include=TRUE}
summary(Model1)
summary(Model2)
summary(Model3)
summary(Model4)

```

#### GLM Step and Best Model Selection
```{r step, echo=TRUE}
base_model <- glm(am ~ ., data = mtcars)
optimal_model <- step(base_model, direction = "both")
summary(optimal_model)
```



#### Evaluating the AIC


```{r pchi, echo=TRUE, include=TRUE}
1-pchisq(Model1$aic,Model1$df.residual)
1-pchisq(Model2$aic,Model2$df.residual)
1-pchisq(Model3$aic,Model3$df.residual)
1-pchisq(Model4$aic,Model4$df.residual)

```

```{r confidenceinterval, echo=TRUE, include=TRUE}
exp(logCars$coefficients)
exp(confint(logCars))
```


```{r carsanova, echo=TRUE}
anova(logCars, test = "Chisq")
```

## Appendix

#### Probability Plot Automatic Transmission


```{r glmplot, echo=TRUE} 
plot(mtcars$mpg,logCars$fitted,pch=19,col="blue",xlab="MPG",ylab="Probability Automatic")
rug(mtcars$mpg, lwd = 2, col = "red")
```


#### Residuals and Fit Plots
```{r residuals, echo=TRUE}
par(mfrow = c(2,2))
plot(logCars)
```

#### Scatterplot Matrix
The plot displays the points for pairs of variables.

```{r pairs, echo=TRUE}
pairs(mpg ~ ., data = mtcars, col = "black")
```





